

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Introduction : Jetson-Inference &mdash; AI_beginner_course 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/SierraBASE.png"/>
  

  
  

  
    <link rel="canonical" href="https://sierrabaselab.github.io/AI_beginner_course/text/#3_Jetson_Opensource.html" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Introduction : Teachble Machine" href="%232_Image_Classification.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> AI_beginner_course
          

          
            
            <img src="../_static/SierraBASE.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Get Started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="%231_Get_Started.html">Install : Prerequisies and Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="%231_Get_Started.html#install-tensorflow">Install : tensorflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="%231_Get_Started.html#download-project">Download : Project</a></li>
</ul>
<p class="caption"><span class="caption-text">Image_classifciation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html">Introduction : Teachble Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#how-to-train">1. How to train</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#inference-and-results">2. Inference and Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#introduction-mnist">Introduction : MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#training-phase">1. Training Phase</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#data-preparation">2. Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#inference">3. Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="%232_Image_Classification.html#faq">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Jetson_Opensources:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction : Jetson-Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="#build-models">1. Build models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#let-s-run-some-files">2. Let’s Run some files</a></li>
<li class="toctree-l1"><a class="reference internal" href="#introduction-nvidia">Introduction : NVIDIA</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AI_beginner_course</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Introduction : Jetson-Inference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/text/" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="introduction-jetson-inference">
<h1>Introduction : Jetson-Inference<a class="headerlink" href="#introduction-jetson-inference" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Jetson</span> <span class="pre">Inference</span></code> is an opensource to introduce Deep Neural Network models, which can run in real-time and accurately. Especially, this repository uses NVIDIA TensorRT for efficiently deploying neural networks onto the embedded Jetson platform(e.g. nano, tx2, xaiver …), improving performance and power efficiency using graph optimizations, kernel fusion, and FP(Float Precision)16/INT8 precision. In more details, refer to <a class="reference external" href="https://github.com/dusty-nv/jetson-inference">this site(github)</a>.</p>
<p>Morerover, it supports to</p>
<ul class="simple">
<li><p>training (Transfer Learning / Re-training)</p>
<ul>
<li><p>Classification</p>
<ul>
<li><p>Cat/Dog Dataset</p></li>
<li><p>PlantCLEF Dataset</p></li>
<li><p>Your Own Image Dataset</p></li>
</ul>
</li>
<li><p>Object Detection</p>
<ul>
<li><p>SSD-Mobilenet Network</p></li>
<li><p>Your Own Detection Dataset</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Inference</p>
<ul>
<li><p>Classification</p>
<ul>
<li><p>Imagenet with Image / Video</p></li>
<li><p>your Own Image</p></li>
</ul>
</li>
<li><p>Object Detection</p>
<ul>
<li><p>Face</p></li>
<li><p>COCO containing dogs, bottles, etc.</p></li>
</ul>
</li>
<li><p>Semantic Segmentation</p>
<ul>
<li><p>Cityspcapes Dataset</p></li>
<li><p>DeepScene Dataset etc.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="build-models">
<h1>1. Build models<a class="headerlink" href="#build-models" title="Permalink to this headline">¶</a></h1>
<p>Note that you need to get ready for download opensource.</p>
<ol>
<li><p>Go into <code class="docutils literal notranslate"><span class="pre">AI_beginner_course/DL_course/</span></code> and download opensource.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> ..
$ git clone https://github.com/dusty-nv/jetson-inference
$ <span class="nb">cd</span> jetson-inference
$ git submodule update --init
</pre></div>
</div>
</li>
<li><p>Set some settings for build.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ mkdir build
$ <span class="nb">cd</span> build
$ cmake ../
</pre></div>
</div>
<p>You might be confused because of the options of cmake. Note that the default models is</p>
<ul class="simple">
<li><p>Image Recoginition</p>
<ul>
<li><p>GoogleNet</p></li>
<li><p>ResNet-18</p></li>
</ul>
</li>
<li><p>Object Detection</p>
<ul>
<li><p>SSD-MobileNet-v2</p></li>
<li><p>PedNet</p></li>
<li><p>FaceNet</p></li>
<li><p>DetectNet-COCO-Dog</p></li>
</ul>
</li>
<li><p>Semantic Segmentation</p>
<ul>
<li><p>FCN-ResNet18-Cityspaces-512x256</p></li>
<li><p>FCN-ResNet18-DeepScene-576x320</p></li>
<li><p>FCN-ResNet18-MHP-512x320</p></li>
<li><p>FCN-ResNet18-Pascal-VOC-320x320</p></li>
<li><p>FCN-ResNet18-SUN-RGBD-512x400</p></li>
</ul>
</li>
</ul>
<p><strong>Just press <code class="docutils literal notranslate"><span class="pre">enter</span></code></strong>(Recommend). If you want to download all, you can select menu, where contains “all models”, by pressing <code class="docutils literal notranslate"><span class="pre">spacebar</span></code>.</p>
<p>Moreover, I recommend to select to install <code class="docutils literal notranslate"><span class="pre">pytorch</span></code></p>
<p>It will take a lot of time( ~ 20 mins).</p>
</li>
<li><p>Let’s build and compile!</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ make -j<span class="k">$(</span>nproc<span class="k">)</span>
$ sudo make install
$ sudo ldconfig
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="let-s-run-some-files">
<h1>2. Let’s Run some files<a class="headerlink" href="#let-s-run-some-files" title="Permalink to this headline">¶</a></h1>
<p>Let’s check the results of pretrained models.</p>
<ol>
<li><p>Image Classification - <a class="reference external" href="http://www.image-net.org/">ImageNet</a></p>
<p>Here it is a basic step)</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> aarch64/bin/
$ python3 imagenet.py /dev/video0
</pre></div>
</div>
<p>Note that the default option of <code class="docutils literal notranslate"><span class="pre">imagenet.py</span></code> file is “network=GoogLeNet”. and “/dev/video0” means your data input sources. Espeically, it means you’ll try a <code class="docutils literal notranslate"><span class="pre">USB</span> <span class="pre">viedo</span> <span class="pre">Camera</span></code>.</p>
<p>You can change other models. Then, let’s change the other model, ResNet-18!!</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ python3 imagenet.py --network<span class="o">=</span>resnet-18 /dev/video0
</pre></div>
</div>
<p>There is a table shows jetson-inference repository supports.</p>
</li>
</ol>
<p>| Network       | CLI argument   | NetworkType enum |
|—————|—————-|——————|
| AlexNet       | <code class="docutils literal notranslate"><span class="pre">alexnet</span></code>      | <code class="docutils literal notranslate"><span class="pre">ALEXNET</span></code>        |
| GoogleNet     | <code class="docutils literal notranslate"><span class="pre">googlenet</span></code>    | <code class="docutils literal notranslate"><span class="pre">GOOGLENET</span></code>      |
| GoogleNet-12  | <code class="docutils literal notranslate"><span class="pre">googlenet-12</span></code> | <code class="docutils literal notranslate"><span class="pre">GOOGLENET_12</span></code>   |
| ResNet-18     | <code class="docutils literal notranslate"><span class="pre">resnet-18</span></code>    | <code class="docutils literal notranslate"><span class="pre">RESNET_18</span></code>      |
| ResNet-50     | <code class="docutils literal notranslate"><span class="pre">resnet-50</span></code>    | <code class="docutils literal notranslate"><span class="pre">RESNET_50</span></code>      |
| ResNet-101    | <code class="docutils literal notranslate"><span class="pre">resnet-101</span></code>   | <code class="docutils literal notranslate"><span class="pre">RESNET_101</span></code>     |
| ResNet-152    | <code class="docutils literal notranslate"><span class="pre">resnet-152</span></code>   | <code class="docutils literal notranslate"><span class="pre">RESNET_152</span></code>     |
| VGG-16        | <code class="docutils literal notranslate"><span class="pre">vgg-16</span></code>       | <code class="docutils literal notranslate"><span class="pre">VGG-16</span></code>         |
| VGG-19        | <code class="docutils literal notranslate"><span class="pre">vgg-19</span></code>       | <code class="docutils literal notranslate"><span class="pre">VGG-19</span></code>         |
| Inception-v4  | <code class="docutils literal notranslate"><span class="pre">inception-v4</span></code> | <code class="docutils literal notranslate"><span class="pre">INCEPTION_V4</span></code>   |</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">You</span> <span class="n">could</span> <span class="n">see</span> <span class="n">the</span> <span class="n">various</span> <span class="n">models</span> <span class="n">before</span> <span class="n">build</span> <span class="n">makes</span><span class="o">.</span> <span class="n">In</span> <span class="n">details</span><span class="p">,</span> <span class="n">please</span> <span class="n">visit</span> <span class="p">[</span><span class="n">this</span> <span class="n">github</span> <span class="n">site</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">dusty</span><span class="o">-</span><span class="n">nv</span><span class="o">/</span><span class="n">jetson</span><span class="o">-</span><span class="n">inference</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<ol>
<li><p>Object Detection</p>
<p>Object Detection models show the bounded boxes we trained.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ python3 detectnet.py /dev/video0
</pre></div>
</div>
<p>In this case, we can check the default network is SSD-MobileNet-V2. and the below table is network model list. and <a class="reference external" href="https://cocodataset.org/#home">COCO</a> is the most used Image Datasets. There are many labelings(Person, chair, animals, … and so on) in COCO Datasets. For training them, we need much times and expensive devices. So we simply introduce object detection’s inference.</p>
<p>| Network                 | CLI argument       | NetworkType enum   | Object classes       |
| ————————|——————–|——————–|———————-|
| SSD-Mobilenet-v1        | <code class="docutils literal notranslate"><span class="pre">ssd-mobilenet-v1</span></code> | <code class="docutils literal notranslate"><span class="pre">SSD_MOBILENET_V1</span></code> | 91 CoCo classes	   |
| SSD-Mobilenet-v2        | <code class="docutils literal notranslate"><span class="pre">ssd-mobilenet-v2</span></code> | <code class="docutils literal notranslate"><span class="pre">SSD_MOBILENET_V2</span></code> | 91 CoCo classes      |
| SSD-Inception-v2        | <code class="docutils literal notranslate"><span class="pre">ssd-inception-v2</span></code> | <code class="docutils literal notranslate"><span class="pre">SSD_INCEPTION_V2</span></code> | 91 CoCo classes      |
| DetectNet-COCO-Dog      | <code class="docutils literal notranslate"><span class="pre">coco-dog</span></code>         | <code class="docutils literal notranslate"><span class="pre">COCO_DOG</span></code>         | dogs                 |
| DetectNet-COCO-Bottle   | <code class="docutils literal notranslate"><span class="pre">coco-bottle</span></code>      | <code class="docutils literal notranslate"><span class="pre">COCO_BOTTLE</span></code>      | bottles              |
| DetectNet-COCO-Chair    | <code class="docutils literal notranslate"><span class="pre">coco-chair</span></code>       | <code class="docutils literal notranslate"><span class="pre">COCO_CHAIR</span></code>       | chairs               |
| DetectNet-COCO-Airplane | <code class="docutils literal notranslate"><span class="pre">coco-airplane</span></code>    | <code class="docutils literal notranslate"><span class="pre">COCO_AIRPLANE</span></code>    | airplanes            |
| ped-100                 | <code class="docutils literal notranslate"><span class="pre">pednet</span></code>           | <code class="docutils literal notranslate"><span class="pre">PEDNET</span></code>           | pedestrians          |
| multiped-500            | <code class="docutils literal notranslate"><span class="pre">multiped</span></code>         | <code class="docutils literal notranslate"><span class="pre">PEDNET_MULTI</span></code>     | pedestrians, luggage |
| facenet-120             | <code class="docutils literal notranslate"><span class="pre">facenet</span></code>          | <code class="docutils literal notranslate"><span class="pre">FACENET</span></code>          | faces                |</p>
</li>
<li><p>Semantic Segmentation.</p>
<p>Object</p>
</li>
</ol>
</div>
<div class="section" id="introduction-nvidia">
<h1>Introduction : NVIDIA<a class="headerlink" href="#introduction-nvidia" title="Permalink to this headline">¶</a></h1>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="%232_Image_Classification.html" class="btn btn-neutral float-left" title="Introduction : Teachble Machine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, SierraBaseLab.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>